## Exercise 5: Retrieval Augmentation Generation (RAG)

Retrieval Augmentation Generation (RAG) is a technique used to improve the accuracy and relevance of responses generated by language models. Suppose you have a collection of documents that you want the language model to reason over and use in it's responses. RAG enables you to provide extra knowledge and context beyond the data that the language model is trained on.

Azure OpenAI On Your Data enables you to run language models on your own enterprise data without needing to train or fine-tune models. You can specify sources to support the responses based on the latest information available in your designated data sources.

Here you'll implement RAG using Azure Open On Your Data to enable the language model to reason over resumes and provide candidate recommendations.

Like we did with the language model, we've already provisioned and configured the services in Azure for you to use.

We provisioned and configured the following resources:

- **Azure Storage Account**: Stores files uploaded through the Azure OpenAI On Your Data file upload feature.
- **Embeddings model**: Generates numerical representations (embeddings) of document contents for use with language models during the file upload process.
- **Azure AI Search**: Hosts the search index of our documents. Contains the document embeddings and additional metadata, such as file paths and timestamps.

### Step 1: Configure Azure AI Search environment variables

First, let's create some environment varibles to store details that we will need to integrate Azure AI Search.

Continuing in Visual Studio:

1. In the **TeamApp** project, expand the **env** folder.
1. Open the **.env.local** file and add the following environment variables:
  
    ```
    AZURE_SEARCH_ENDPOINT=https://aais-ignite-2024-labs.search.windows.net
    AZURE_SEARCH_INDEX_NAME=documents
    ```

1. Save your changes.

In a web browser:

1. In the address bar, type +++https://gist.github.com/garrytrinder/0da49ec4ba50b023e5b75a1c14fa1f22+++ and navigate to a GitHub gist containing environment variables.
1. Copy the value of the **SECRET_AZURE_SEARCH_KEY** variable to your clipboard.

Continue in Visual Studio:

1. In the **TeamApp** project, expand the **env** folder.
1. Open the **.env.local.user** file and add a new environment variable, replacing [INSERT KEY] with the value stored in your clipboard.

    ```
    SECRET_AZURE_SEARCH_KEY=[INSERT KEY]
    ```

1. Save your changes.

Next, let's make sure that these value are written to the **appsettings.development.json** file so we can access them at runtime in our agent code.

1. In the **Custom.Engine.Agent** project, open **teamsapp.local.yml** file.
1. Update the **file/createOrUpdateJsonFile** action with the new environment variables:

    ```
    AZURE_SEARCH_ENDPOINT: ${{AZURE_SEARCH_ENDPOINT}}
    AZURE_SEARCH_INDEX_NAME: ${{AZURE_SEARCH_INDEX_NAME}}
    AZURE_SEARCH_KEY: ${{SECRET_AZURE_SEARCH_KEY}}
    ```

> [!IMPORTANT]
> YAML is strict when it comes to indendation, make sure you indent the YAML after pasting by using tabs to remove the errors in the editor.

1. Save your changes.

The **file/createOrUpdateJsonFile** should look like:

```
- uses: file/createOrUpdateJsonFile
    with:
    target: ../Custom.Engine.Agent/appsettings.Development.json
    content:
        BOT_ID: ${{BOT_ID}}
        BOT_PASSWORD: ${{SECRET_BOT_PASSWORD}}
        AZURE_OPENAI_DEPLOYMENT_NAME: ${{AZURE_OPENAI_DEPLOYMENT_NAME}}
        AZURE_OPENAI_KEY: ${{SECRET_AZURE_OPENAI_API_KEY}}
        AZURE_OPENAI_ENDPOINT: ${{AZURE_OPENAI_ENDPOINT}}
        AZURE_STORAGE_CONNECTION_STRING: UseDevelopmentStorage=true
        AZURE_STORAGE_BLOB_CONTAINER_NAME: state
        AZURE_SEARCH_ENDPOINT: ${{AZURE_SEARCH_ENDPOINT}}
        AZURE_SEARCH_INDEX_NAME: ${{AZURE_SEARCH_INDEX_NAME}}
        AZURE_SEARCH_KEY: ${{SECRET_AZURE_SEARCH_KEY}}
```

Now, extend the model so we can easily access the new environment variable values in code.

1. Open **Config.cs**, update the **ConfigOptions** class, add the following properties:

    ```
    public string AZURE_SEARCH_ENDPOINT { get; set; }
    public string AZURE_SEARCH_INDEX_NAME { get; set; }
    public string AZURE_SEARCH_KEY { get; set; }
    ```

1. Save your changes.

The **ConfigOptions** class should look like:

```
public class ConfigOptions
{
    public string BOT_ID { get; set; }
    public string BOT_PASSWORD { get; set; }
    public string AZURE_OPENAI_KEY { get; set; }
    public string AZURE_OPENAI_ENDPOINT { get; set; }
    public string AZURE_OPENAI_DEPLOYMENT_NAME { get; set; }
    public string AZURE_STORAGE_CONNECTION_STRING { get; set; }
    public string AZURE_STORAGE_BLOB_CONTAINER_NAME { get; set; }
    public string AZURE_SEARCH_ENDPOINT { get; set; }                  
    public string AZURE_SEARCH_INDEX_NAME { get; set; }                
    public string AZURE_SEARCH_KEY { get; set; }
}
```

### Step 2: Integrate Azure AI Search in prompt template configration

Update the prompt template configuration file to integrate Azure OpenAI On Your Data data source.

Continuing in Visual Studio:

1. In the **Custom.Engine.Agent** project, expand the **Prompts** folder.
1. Expand the **Chat** folder and open the **config.json** file. Replace the file contents with the following code:

    ```
    {
      "schema": 1.1,
      "description": "Custom engine agent",
      "type": "completion",
      "completion": {
        "model": "gpt-4",
        "completion_type": "chat",
        "include_history": true,
        "include_input": true,
        "max_input_tokens": 100,
        "max_tokens": 1000,
        "temperature": 0.1,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "data_sources": [
          {
            "type": "azure_search",
            "parameters": {
              "endpoint": "$azure-search-endpoint$",
              "index_name": "$azure-search-index-name$",
              "authentication": {
                "type": "api_key",
                "key": "$azure-search-key$"
              }
            }
          }
        ]
      }
    }
    ```

1. Save your changes.

Let's examine some of the key changes made to the configuration. 

The properties **temperature** and **top_p** control the creativity, or randomness of language model outputs. To take a simple view, language models work by selecting the next probable word (token).

- **temperature**: Has been lowered to **0.1**. Instructs the model to be more deterministic, choosing only the most probable tokens in it's reasoning.
- **top_p**: Has been increased to **1**. Instructs the model to choose from the widest pool of words (tokens) possible in it's reasoning.

These changes optimise the language model for use in scenarios where precision and unambiguity is critical. You should always consider adjusting these parameters to be appropriate for your use case.

Azure OpenAI On Your Data integration is defined in the **data_sources** array. Here we define our configuration providing the minimum required information needed to use the retrieve documents from the Azure AI Search index in the model's reasoning process.

Notice that we use placeholders as values for some properties, for example **$azure-search-key$**, in the configuration file. These placeholders will be updated dynamically in code to ensure that we don't store senstitive information in plain text.

### Step 3: Replace prompt template configuration placeholders with values

Continuing in Visual Studio:

1. Open **Program.cs** file.
1. Replace the contents of the **defaultPrompt** function to dynamically replace the placeholders in the prompt template configuration with the values we stored in our environment variable files earlier.

    ```
    PromptTemplate template = prompts.GetPrompt("Chat");

    var dataSources = template.Configuration.Completion.AdditionalData["data_sources"];
    var dataSourcesString = JsonSerializer.Serialize(dataSources);

    var replacements = new Dictionary<string, string>
    {
        { "$azure-search-key$", config.AZURE_SEARCH_KEY },
        { "$azure-search-index-name$", config.AZURE_SEARCH_INDEX_NAME },
        { "$azure-search-endpoint$", config.AZURE_SEARCH_ENDPOINT },
    };

    foreach (var replacement in replacements)
    {
        dataSourcesString = dataSourcesString.Replace(replacement.Key, replacement.Value);
    }

    dataSources = JsonSerializer.Deserialize<JsonElement>(dataSourcesString);
    template.Configuration.Completion.AdditionalData["data_sources"] = dataSources;

    return await Task.FromResult(template);
    ```

1. Save your changes.

The **ActionPlanner** object should look like:

```
ActionPlanner<TurnState> planner = new(
    options: new(
        model: sp.GetService<OpenAIModel>(),
        prompts: prompts,
        defaultPrompt: async (context, state, planner) =>
        {
            PromptTemplate template = prompts.GetPrompt("Chat");

            var dataSources = template.Configuration.Completion.AdditionalData["data_sources"];
            var dataSourcesString = JsonSerializer.Serialize(dataSources);

            var replacements = new Dictionary<string, string>
            {
                { "$azure-search-key$", config.AZURE_SEARCH_KEY },
                { "$azure-search-index-name$", config.AZURE_SEARCH_INDEX_NAME },
                { "$azure-search-endpoint$", config.AZURE_SEARCH_ENDPOINT },
            };

            foreach (var replacement in replacements)
            {
                dataSourcesString = dataSourcesString.Replace(replacement.Key, replacement.Value);
            }

            dataSources = JsonSerializer.Deserialize<JsonElement>(dataSourcesString);
            template.Configuration.Completion.AdditionalData["data_sources"] = dataSources;

            return await Task.FromResult(template);
        }
    )
    { LogRepairs = true },
    loggerFactory: loggerFactory
);
```

The **defaultPrompt** anonymous function provides a way to dyanmically alter the behaviour of our agent. This is where you can include logic to choose different prompt templates for different functions or behaviours that you want the agent to provide. Suppose you want to dynamically adjust the temperature or choose a different prompt template based in a specific input. Here is where you would add the logic to make those changes on the fly.

### Step 4: Update prompt template

Now, update the prompt text to reflect the change in agent behaviour.

1. In the **Custom.Engine.Agent** project, expand the **Prompts** folder, then expand the **chat** folder.
1. Open the **skprompt.txt** file, then replace the contents with the following:

    ```
    You are a career specialist named "Career Genie" that helps Human Resources team for finding the right candidate for the jobs. 
    You are friendly and professional.
    You always greet users with excitement and introduce yourself first.
    You like using emojis where appropriate.
    Always mention all citations in your content.
    ```

### Step 5: Run and debug

As we've made a change to the app manifest file, we need to Run the Prepare Teams App Dependencies process to update the app registration in the Teams Developer Portal before starting a debug session to test it.

Continuing in Visual Studio:

1. Right-click **TeamsApp** project, expand the **Teams Toolkit** menu and select **Prepare Teams App Dependencies**.
1. Confirm the prompts and wait till the process completes.

Now let's test the change.

1. Start a debug session, press <kbd>F5</kbd> on your keyboard, or select the **Start** button in the toolbar. 

Continuing in the web browser:

1. In the app dialog, select **Open** to open the agent in Microsoft Teams.
1. In the message box, enter +++Can you suggest a candidate who is suitable for spanish speaking role that requires at least 2 years of .NET experience?+++ and send the message. Wait for the response.

Note that the response contains a reference to a document. The document was used by the language model in it's reasoning when generating an answer and provided as part of the answer. Hover over the reference in the response to view more information about the document.

Try out some more prompts and review the outputs, for example:

- +++Who would be suitable for a position that requires 5+ python development experience?+++

Close the browser to stop the debug session.